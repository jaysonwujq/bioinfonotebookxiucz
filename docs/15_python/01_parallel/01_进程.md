## 
+ subprocess.Popen
+ subprocess.call
  + shell参数为true，则命令以及参数以字符串的形式给出
  + shell参数为false，则命令以及参数以列表的形式给出
  + 最后一个状态0，表示命令执行成功。
+ subprocess.check_call
  + 用法与subprocess.call()类似，区别是，当返回值不为0时，直接抛出异常
+ subprocess.check_output()

----
**Process vs. Pool**
+ Pool和之前的Process的不同点是丢向Pool的函数有返回值，而Process的没有返回值。

**apply_async vs. apply**
+ `pool.apply_async`采用异步方式调用task，`pool.apply` 则是同步方式调用,同步方式意味着下一个task需要等待上一个task完成后才能开始运行。
+ apply_async()中只能传递一个值，它只会放入一个核进行运算，但是传入值时要注意是可迭代的，所以在传入值后需要加逗号, 同时需要用get()方法获取返回值
+ map() 放入迭代参数，返回多个结果
+ apply_async()只能放入一组参数，并返回一个结果，如果想得到map()的效果需要通过迭代

## Process
```{python}
def task(x):
    # 获取子进程ID
    proc_id = os.getpid()
    # 获取子进程名称
    proc_name = current_process().name
    print('Run child process %s (%s)...' % (name, proc_id))
    return x*x

if __name__ == '__main__':
    #父进程
    print('parent_proc_id:{0} parent_proc_name:{1}'.format( \
    os.getpid(), current_process().name))
    #print('Parent process %s.' % os.getpid())

    #创建子进程
    proc = Process(target=task, args=('test',))
    print('Child process will start.')
    proc.start()
    #join()方法可以让父进程等待子进程结束后再继续往下运行，通常用于进程间的同步。
    proc.join() 
    print('Child process end.')
``` 
### 继承式调用
```
import time
import random
from multiprocessing import Process


class Run(Process):
    def __init__(self, name):
        #必须调用父类的init方法
        super(Run, self).__init__()
        self.name = name
    def run(self):
        print('%s runing' %self.name)
        time.sleep(random.randrange(1,5))
        print('%s runing end' %self.name)

p1=Run('anne')
p2=Run('alex')
p3=Run('ab')
p4=Run('hey')
p1.start() #start会自动调用run
p2.start()
p3.start()
p4.start()
print('主线程')
```

## 守护进程
----
## Pool
```
def task(x):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    end = time.time()
    print('Task %s runs %0.2f seconds.' % (name, (end - start)))
    return x*x

def multicore_map():
    pool = multiprocessing.Pool()
    res = pool.map(task, range(4))
    print(res)
    

def multicore_async():
    print('Parent process %s.' % os.getpid())
    pool = multiprocessing.Pool(4)
    results = []
    for i in xrange(0, 4):
#使用线程池建立子进程        
        result = pool.apply_async(task, args=(i,))
        results.append(result)
    print('Waiting for all subprocesses done...')
    pool.close() #调用join()之前必须先调用close()，调用close()之后就不能继续添加新的Process了。
    # 关闭pool，结束工作进程，不在处理未完成的任务
    # pool.terminate()
    pool.join()  #对Pool对象调用join()方法会等待所有子进程执行完毕。
    print('All subprocesses done.')
    for result in results:
        print(result.get())

#multi_res = [pool.apply_async(job, (i,)) for i in range(10)]
#print([res.get() for res in multi_res])

```
> 在这里不免有人要疑问，为什么不直接在 for 循环中直接 result.get()呢？这是因为pool.apply_async之后的语句都是阻塞执行的，调用 result.get() 会等待上一个任务执行完之后才会分配下一个任务。事实上，获取返回值的过程最好放在进程池回收之后进行，避免阻塞后面的语句。

----
```
#CPU核心数
cpus = multiprocessing.cpu_count()
```

https://morvanzhou.github.io/tutorials/python-basic/multiprocessing/3-queue/
https://www.cnblogs.com/jiangfan95/p/11439207.html
https://www.cnblogs.com/luyuze95/p/11266951.html


#
```
from multiprocessing import Process
import os

def square_numbers():
    for i in range(1000):
        result = i * i
        print(result)

if __name__ == "__main__":
    processes = []
    num_processes = os.cpu_count()
    # number of CPUs on the machine. Usually a good choise for the number of processes

    # create processes and asign a function for each process
    for i in range(num_processes):
        process = Process(target=square_numbers)
        processes.append(process)

    # start all processes
    for process in processes:
        process.start()

    # wait for all processes to finish
    # block the main programm until these processes are finished
    for process in processes:
        process.join()
```

https://www.python-engineer.com/courses/advancedpython/17-multiprocessing/
https://www.python-engineer.com/courses/advancedpython/15-thread-vs-process/
https://www.python-engineer.com/courses/advancedpython/16-threading/