# SRA数据下载：

## 搜索数据：
```
PRJNA438770
==>
https://www.ncbi.nlm.nih.gov/Traces/study/
==>
https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA438770&o=acc_s%3Aa
https://www.ncbi.nlm.nih.gov/Traces/study1/?acc=PRJNA438770(旧版)
==>
获取得到SRR_Acc_List.txt

#这种方法容易漏数据
PRJNA438770
==>
https://www.ncbi.nlm.nih.gov/sra/?term=PRJNA438770
==>
选中符合要求的数据，然后点击send to，RunInfo
==>
获取得到SraRunInfo.csv
```

## 下载方法
### ascp

根据电脑版本下载对应aspera connect server，下载地址：http://downloads.asperasoft.com/en/downloads/4

```
#NCBI
ftp://ftp.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/SRR690/SRR6904179/SRR6904179.sra


#ENA
http://ftp.sra.ebi.ac.uk/vol1/fastq/SRR121/SRR121621/SRR121621_1.fastq.gz

ascp -QT -l 300m -P 33001 -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/SRR121/SRR121621/SRR121621_1.fastq.gz path/to/download_dir

```

批量处理(旧版)
```
ftp='era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq'

mkdir sra  # make a output directory
cat SRR_Acc_List.txt |  while read i
 do
       SRR=$(echo ${i:0:6}) 
       # ascp -QT -l 300m -P 33001 -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh ${ftp}/${SRR}/${i}/{i}.fastq.gz ./sra 单端测序的话只有这一个文件
       ascp -QT -l 300m -P 33001 -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh ${ftp}/${SRR}/${i}/${i}_1.fastq.gz ./sra
       ascp -QT -l 300m -P 33001 -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh ${ftp}/${SRR}/${i}/${i}_2.fastq.gz ./sra
 done
```
批量处理
```
ftp='era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq'

cat>SRR_Acc_List.txt.download.parallel<<stop
stop

cat SRR_Acc_List.txt |  while read i
do
SRR=$(echo ${i:0:6}) ;  tmp_flag=$(echo 00${i:0-1:1});
cat>>SRR_Acc_List.txt.download.parallel<<stop
  ~/.aspera/connect/bin/ascp -QT -l 300m -P 33001 \
  -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh \
  ${ftp}/${SRR}/${tmp_flag}/${i}/${i}_1.fastq.gz ./sra_fq \
  && \
  ~/.aspera/connect/bin/ascp -QT -l 300m -P 33001 \
  -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh \
  ${ftp}/${SRR}/${tmp_flag}/${i}/${i}_2.fastq.gz ./sra_fq \
  && touch ./sra_fq/$i.success || touch ./sra_fq/$i.error
stop
done
```
### prefetch下载SRA文件然后用fastq-dump转为fastq文件
```
prefetch SRR11448442 -O `pwd` && echo "** SRR11448442.sra done **"
time fastq-dump --gzip --split-files -A SRR11448442 SRR11448442.sra && echo "** SRR11448442.sra to fastq done **"

cat SRR_Acc_List.txt | while read id; do (prefetch  ${id} );done
```

### SRATookit下载
  + NCBI 提供的下载软件
  + https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software
### ENA
https://www.ebi.ac.uk/ena/browser/home

### SRA Explorer(https://sra-explorer.info/#)
### 迅雷下载

生成`ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/SRR563/SRR5631562/SRR5631562.sra` 格式，粘贴到迅雷中

注：头部都一样(黑色字)，后面地址分别为SRR，SRR+前三个数、SRR号、SSR号.sra
```
cat sra.txt|while read a ;do t1=${a:0:3};t2=${a:0:6};echo "ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/$t1/$t2/$a/$a.sra";done
```

### wget 
```
ftp='http://ftp.sra.ebi.ac.uk/vol1/fastq'

mkdir sra  # make a output directory
cat SRR_Acc_List.txt |  while read i
 do
       SRR=$(echo ${i:0:6}) 
       # wget -c -t 0 -P ./sra ${ftp}/${SRR}/${i}/${i}.fastq.gz 单端只有一个文件
       wget -c -t 0 -P ./sra ${ftp}/${SRR}/${i}/${i}_1.fastq.gz
       wget -c -t 0 -P ./sra ${ftp}/${SRR}/${i}/${i}_2.fastq.gz
 done
```

----

rsync断点续传
网络传输速度很大程度上会影响我的工作。服务器与服务器之间的通连，有时scp不是最好的选择，例如：网络出现问题，两个服务器之间的连接断开后，使用scp再次连接时无法进行断点续传。

使用rsync做服务器之间的文件传输（备份），可以做到断点续传。

rsync -avzP -e 'ssh -p 8888' abc@xxx.xxx.xxx.xxxx:/home/abc/filename ./
wget并行下载
-P 8八线程，-t 0无限重试，-nv 下载时只显示更新和出错信息，不显示指令的详细执行过程

就是输入的地址urls.txt，每一行用一个wget命令进行下载，一次最多同时下载8个文件。

xargs -P 8 -n 1 wget -nv -c -t 0 <urls.txt
wget下载动态连接的文件
wget -c 'http://some.site.com/download?id=234&status=download' -O output_filename
随时上网检索一下，上面这个方法不一定每个动态连接的文件都能下载，例如google网盘的。

aria2分段下载大文件
-s 3 分成3份，-x 3 用3个连接从服务器下载文件
```
aria2c  -s 3 -x 3 "https://baidu.com/d/datadump.current.zip"
```
bypy将百度云盘数据下载到服务器
安装信息：(bypy)[https://github.com/houtianze/bypy]

测试发现，大文件上传比慢。文件只能上传到全部文件>apps>bypy这个文件夹。

下载一系列FTP上的文件
这是压箱底的老程序，filetype这里其实不需要使用一个循环，如果只有一个类型的话，直接在下载的循环中用grep筛出这个变量。
```
#!/bin/bash

for filetype in pdf; 
do 
  for net in `grep "$filetype" file.list2 | sed "s/\<td\>\<a href=\"//g" | sed "s/\"//g" | sed "s/<TD//g"`; 
  do 
    if [ ! -f $net ]
    then
    echo $net
    #wget  $path/$net
    fi
  done
done
```




https://www.jianshu.com/p/d587728acc52